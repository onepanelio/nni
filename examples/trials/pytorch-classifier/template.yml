entrypoint: main
arguments:
    parameters:
    - name: cvat-annotation-path
      value: annotation-dump/patch_medical/compressed_valid
      displayName: Dataset path
      hint: Path to annotated data in default object storage (i.e S3). In CVAT, this parameter will be pre-populated.
      visibility: private
      
    - name: cvat-output-path
      value: workflow-data/output/nas/nas-model-comparison
      visibility: private
      
    - name: num-classes
      displayName: Number of classes
      visibility: public
      value: '2'
      hint: 'Number of classes in a dataset'
      
    - name: test-split
      displayName: Percentage of images to use for testing
      visibility: public
      value: '20'
      hint: 'Percentage of data to be used for test set'
      
    - name: skip-preprocessing
      displayName: Whether to skip preprocessing data or not
      visibility: public
      value: 'true'
      hint: 'Specify whether to skip preprocessing or not. Skip preprocessing if your dataset is already in a required format.'
      
    - name: searchspace-config
      type: textarea.textarea
      displayName: Search space for hyperparameter tuning
      value: |-
        batch_size_list=16,32,64,128   # batch sizes for hyperparameter tuner
        lr_list=0.0001,0.001,0.01,0.1  # learning rates for hyperparameter tuner
        momentum_range=0,1             # range for momentum for hyperparameter tuner
        epochs=10                      # epochs to train each model for
      hint: 'Define parameters for hyperparameter tuning'
        
    - name: nas-config
      value: |-
        epochs=20                     # epochs to train a model for
        batch_size=128                # batch size for training
        search_for=macro              # macro or micro search technique for ENAS
      displayName: Settings for Neural Architecture Search
      visibility: public
      hint: 'Define parameters for Neural Architecture Search'
      
      type: textarea.textarea
    - name: fixedparam-config
      value: |-
        momentum=0.5                  # momentum to use for training
        lr=0.01                       # learning rate for training
        model_type=alexnet            # model to train (i.e alexnet, googlenet)
        batch_size=16                 # batch size for training
        epochs=10                     # epochs to train a model for
      displayName: Settings for model training
      visibility: public
      type: textarea.textarea
    
    - displayName: Node pool
      hint: Name of node pool or group to run this workflow task
      type: select.select
      visibility: public
      name: sys-node-pool
      value: Standard_D4s_v3
      required: true
      options:
      - name: 'CPU: 2, RAM: 8GB'
        value: Standard_D2s_v3
      - name: 'CPU: 4, RAM: 16GB'
        value: Standard_D4s_v3
      - name: 'GPU: 1xK80, CPU: 6, RAM: 56GB'
        value: Standard_NC6
      - name: 'GPU: 1xV100, CPU: 6, RAM: 56GB'
        value: Standard_NC6s_v3
    
volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
  - metadata:
      name: output
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
  - metadata:
      name: hyperparamtuning-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
  - metadata:
      name: hyperparamtuning-output
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
  - metadata:
      name: fixedparam-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
  - metadata:
      name: fixedparam-output
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
  - metadata:
      name: comparemodel-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
  - metadata:
      name: comparemodel-output
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: preprocess-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: preprocess-output
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
templates:
  - name: main
    dag:
      tasks:
      - name: process-data
        template: process-data
      - name: neural-architecture-search
        template: pytorch
        dependencies: [process-data]
      - name: hyperparameter-tuning
        template: hyperop
        dependencies: [process-data]
      - name: train-model
        template: model-param
        dependencies: [process-data]
      - name: compare-models
        template: compare-models
        dependencies: [neural-architecture-search, hyperparameter-tuning, train-model]
        arguments:
          artifacts:
            - name: nas-metrics
              from: "{{tasks.neural-architecture-search.outputs.artifacts.sys-metrics}}" 
            - name: hyperop-metrics
              from: "{{tasks.hyperparameter-tuning.outputs.artifacts.sys-metrics}}"
            - name: singlemodel-metrics
              from: "{{tasks.train-model.outputs.artifacts.sys-metrics}}"
  - name: pytorch
    inputs:
      artifacts:
      - name: data
        path: /mnt/data/datasets/
        s3:
          key: '{{workflow.namespace}}/{{workflow.parameters.cvat-output-path}}/{{workflow.name}}'
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        archive:
          none: {}
    container:
      image: onepanel/nni:1.0.0
      command: [sh,-c]
      args:
      - |
        mv /mnt/data/datasets/processed_data.zip ./ && \
        unzip processed_data.zip -d /mnt/data/datasets/ && \
        git clone --single-branch --branch fix/config_param https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 examples/nas/enas/search.py \
              --config="{{workflow.parameters.nas-config}}" \
              --num-classes="{{workflow.parameters.num-classes}}" \
              --dataset="custom_classification" \
              --train-data-dir="/mnt/data/datasets/processed_data/train" \
              --valid-data-dir="/mnt/data/datasets/processed_data/test"
      workingDir: /mnt
      volumeMounts:
      - name: data
        mountPath: /mnt/data
      - name: output
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'
    sidecars:
      - name: nni-nas-ui
        image: 'tensorflow/tensorflow:2.3.0'
        command:
          - sh
          - '-c'
        tty: true
        args:
          - |
            pip install nni && \
            nnictl webui nas --logdir /mnt/output/naslogs --port 8888
        ports:
          - containerPort: 8888
            name: nni

  - name: hyperop
    inputs:
      artifacts:
      - name: data
        path: /mnt/data/datasets/
        s3:
          key:  '{{workflow.namespace}}/{{workflow.parameters.cvat-output-path}}/{{workflow.name}}'
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        archive:
          none: {}
    container:
      image: onepanel/nni:1.0.0
      command: [sh,-c]
      args:
      - |
        mv /mnt/data/datasets/processed_data.zip ./ && \
        unzip processed_data.zip -d /mnt/data/datasets/ && \
        git clone --single-branch --branch fix/config_param https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 examples/trials/pytorch-classifier/create_yaml.py \
            --config="{{workflow.parameters.searchspace-config}}" \
            --num_classes="{{workflow.parameters.num-classes}}" && \
        nnictl create --config examples/trials/pytorch-classifier/config.yml --port 8089 --foreground
      workingDir: /mnt
      volumeMounts:
      - name: hyperparamtuning-data
        mountPath: /mnt/data
      - name: hyperparamtuning-output
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'
    sidecars:
      - name: nni-hyperparamopt-ui
        image: 'onepanel/nni-proxy:0.0.1'
        tty: true
        ports:
          - containerPort: 8089
            name: nni
    
  - name: model-param
    inputs:
      artifacts:
      - name: data
        path: /mnt/data/datasets/
        s3:
          key: '{{workflow.namespace}}/{{workflow.parameters.cvat-output-path}}/{{workflow.name}}'
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        archive:
          none: {}
    container:
      image: onepanel/nni:1.0.0
      command: [sh,-c]
      args:
      - |
        mv /mnt/data/datasets/processed_data.zip ./ && \
        unzip processed_data.zip -d /mnt/data/datasets/ && \
        git clone --single-branch --branch fix/config_param https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 examples/trials/pytorch-classifier/train_model.py \
              --num_classes="{{workflow.parameters.num-classes}}" \
              --train_dir="/mnt/data/datasets/processed_data/train" \
              --test_dir="/mnt/data/datasets/processed_data/test" \
              --config="{{workflow.parameters.fixedparam-config}}" \
              --log_interval=1
      workingDir: /mnt
      volumeMounts:
      - name: fixedparam-data
        mountPath: /mnt/data
      - name: fixedparam-output
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'
    sidecars:
      - name: tensorboard
        image: 'tensorflow/tensorflow:2.3.0'
        command:
          - sh
          - '-c'
        tty: true
        args:
          - tensorboard --logdir /mnt/output/fixed_param_tb
        ports:
          - containerPort: 6006
            name: tensorboard
   
  - name: compare-models
    inputs:
      artifacts:
      - name: nas-metrics
        path: /tmp/nas-metrics.json
      - name: hyperop-metrics
        path: /tmp/hyperop-metrics.json
      - name: singlemodel-metrics
        path: /tmp/singlemodel-metrics.json
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        archive:
          none: {}
    container:
      image: onepanel/nni:1.0.0
      command: [sh,-c]
      args:
      - |
        git clone --single-branch --branch fix/config_param https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 compare.py
      workingDir: /mnt
      volumeMounts:
      - name: comparemodel-data
        mountPath: /mnt/data
      - name: comparemodel-output
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'
   
  - name: process-data
    inputs:
      artifacts:
      - name: data
        path: /mnt/data/datasets/
        s3:
          key: '{{workflow.namespace}}/{{workflow.parameters.cvat-annotation-path}}'
    
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        s3:
          key: '{{workflow.namespace}}/{{workflow.parameters.cvat-output-path}}/{{workflow.name}}'
    container:
      image: pytorch/pytorch:latest
      command: [sh,-c]
      args:
      - |
        apt-get update && \
        apt-get install -y gcc g++ git unzip zip && \
        python3 -m pip install setuptools && \
        cd /mnt/data/datasets && \
        unzip processed_data.zip && \
        rm -f processed_data.zip && \
        cd /mnt && \
        git clone --single-branch --branch fix/config_param https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 prepare_data.py --data_dir="./processed_data" \
                                --test_split="{{workflow.parameters.test-split}}" \
                                --skip="{{workflow.parameters.skip-preprocessing}}" && \
        zip -r /mnt/output/processed_data.zip ./processed_data
      workingDir: /mnt
      volumeMounts:
      - name: preprocess-data
        mountPath: /mnt/data
      - name: preprocess-output
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'