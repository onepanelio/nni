entrypoint: main
arguments:
    parameters:
    - name: source
      value: https://github.com/onepanelio/nni.git
    - name: cvat-annotation-path
      value: annotation-dump/animals/11052020231652
      displayName: Dataset path
      hint: Path to annotated data in default object storage (i.e S3). In CVAT, this parameter will be pre-populated.
      visibility: private
    - name: cvat-output-path
      value: workflow-data/output/nas/nas-model-comparison
      visibility: private
    - name: num-classes
      displayName: Number of classes
      visibility: public
      value: 2
    - name: learning-rate
      value: 0.01
      displayName: Learning rate
      visibility: public
    - name: batch-size
      value: 1
      displayName: Batch size
      visibility: public
    - name: momentum
      value: 0.5
      displayName: Momentum
      visibility: public
    - name: model-type
      displayName: Model type
      visibility: public
      value: alexnet
      options:
      - name: 'GoogleNet'
        value: 'googlenet'
      - name: 'ResNet50'
        value: 'resnet50'
    - name: epochs
      value: 1
    - name: search-method
      value: macro
      type: select.select
      options:
      - name: 'Macro'
        value: macro
      - name: 'Micro'
        value: micro
    - displayName: Node pool
      hint: Name of node pool or group to run this workflow task
      type: select.select
      visibility: public
      name: sys-node-pool
      value: Standard_D4s_v3
      required: true
      options:
      - name: 'CPU: 2, RAM: 8GB'
        value: Standard_D2s_v3
      - name: 'CPU: 4, RAM: 16GB'
        value: Standard_D4s_v3
      - name: 'GPU: 1xK80, CPU: 6, RAM: 56GB'
        value: Standard_NC6
      - name: 'GPU: 1xV100, CPU: 6, RAM: 56GB'
        value: Standard_NC6s_v3
    
volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: output
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: data2
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: output2
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: data3
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: output3
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: data4
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: output4
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: data5
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  - metadata:
      name: output5
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
templates:
  - name: main
    dag:
      tasks:
      - name: process-data
        template: process-data
      - name: neural-architecture-search
        template: pytorch
        dependencies: [process-data]
      - name: hyperparameter-tuning
        template: hyperop
        dependencies: [process-data]
      - name: train-model
        template: model-param
        dependencies: [process-data]
      - name: compare-models
        template: compare-models
        dependencies: [neural-architecture-search, hyperparameter-tuning, train-model]
        arguments:
          artifacts:
            - name: nas-metrics
              from: "{{tasks.neural-architecture-search.outputs.artifacts.sys-metrics}}" 
            - name: hyperop-metrics
              from: "{{tasks.hyperparameter-tuning.outputs.artifacts.sys-metrics}}"
            - name: singlemodel-metrics
              from: "{{tasks.model-param.outputs.artifacts.sys-metrics}}"
  - name: pytorch
    inputs:
      artifacts:
      - name: data
        path: /mnt/data/datasets/
        s3:
          key: '{{workflow.namespace}}/{{workflow.parameters.cvat-output-path}}/{{workflow.name}}'
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        archive:
          none: {}
    container:
      image: pytorch/pytorch:latest
      command: [sh,-c]
      args:
      - |
        apt-get update && \
        apt-get install -y gcc g++ git && \
        python3 -m pip install setuptools torch==1.4.0 torchvision==0.5.0 tensorboard && \
        git clone --single-branch --branch dev https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 setup.py install && \
        python3 examples/nas/enas/search.py --search-for {{workflow.parameters.search-method}} --epochs {{workflow.parameters.epochs}} --num-classes {{workflow.parameters.num-classes}} \
                --dataset custom_classification --train-data-dir /mnt/data/datasets/processed_data --valid-data-dir /mnt/data/datasets/processed_data
      workingDir: /mnt
      volumeMounts:
      - name: data
        mountPath: /mnt/data
      - name: output
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'

  - name: hyperop
    inputs:
      artifacts:
      - name: data
        path: /mnt/data/datasets/
        s3:
          key:  '{{workflow.namespace}}/{{workflow.parameters.cvat-output-path}}/{{workflow.name}}'
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        archive:
          none: {}
    container:
      image: pytorch/pytorch:latest
      command: [sh,-c]
      args:
      - |
        apt-get update && \
        apt-get install -y gcc g++ git && \
        python3 -m pip install setuptools torch==1.4.0 torchvision==0.5.0 tensorboard && \
        git clone --single-branch --branch dev https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 setup.py install && \
        python3 examples/trials/pytorch-classifier/main.py --model_type={{workflow.parameters.model-type}} --epochs {{workflow.parameters.epochs}} --num_classes {{workflow.parameters.num-classes}} \
                 --train_dir /mnt/data/datasets/processed_data --test_dir /mnt/data/datasets/processed_data
      workingDir: /mnt
      volumeMounts:
      - name: data2
        mountPath: /mnt/data
      - name: output2
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'
    
  - name: model-param
    inputs:
      artifacts:
      - name: data
        path: /mnt/data/datasets/
        s3:
          key: '{{workflow.namespace}}/{{workflow.parameters.cvat-output-path}}/{{workflow.name}}'
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        archive:
          none: {}
    container:
      image: pytorch/pytorch:latest
      command: [sh,-c]
      args:
      - |
        apt-get update && \
        apt-get install -y gcc g++ git && \
        python3 -m pip install setuptools torch==1.4.0 torchvision==0.5.0 tensorboard && \
        git clone --single-branch --branch dev https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 setup.py install && \
        python3 examples/trials/pytorch-classifier/train_model.py --model_type={{workflow.parameters.model-type}} --epochs {{workflow.parameters.epochs}} --num_classes {{workflow.parameters.num-classes}} \
                 --train_dir /mnt/data/datasets/processed_data --test_dir /mnt/data/datasets/processed_data --lr {{workflow.parameters.learning-rate}} --momentum {{workflow.parameters.momentum}} --batch_size {{workflow.parameters.batch-size}}
      workingDir: /mnt
      volumeMounts:
      - name: data3
        mountPath: /mnt/data
      - name: output3
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'
    
   
  - name: compare-models
    inputs:
      artifacts:
      - name: data
        path: /mnt/data/datasets/
        s3:
          key: '{{workflow.namespace}}/{{workflow.parameters.cvat-annotation-path}}'
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        archive:
          none: {}
    container:
      image: pytorch/pytorch:latest
      command: [sh,-c]
      args:
      - |
        apt-get update && \
        apt-get install -y gcc g++ git && \
        python3 -m pip install setuptools torch==1.4.0 torchvision==0.5.0 tensorboard && \
        git clone --single-branch --branch dev https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 setup.py install && \
        python3 prepare_data.py && \
        python3 examples/trials/pytorch-classifier/train_main.py --model_type={{workflow.parameters.model-type}} --epochs {{workflow.parameters.epochs}} --num_classes {{workflow.parameters.num-classes}} \
                 --train_dir /mnt/data/datasets/processed_data --test_dir /mnt/data/datasets/processed_data --lr {{workflow.parameters.learning-rate}} --momentum {{workflow.parameters.momentum}} --batch_size {{workflow.parameters.batch-size}}
      workingDir: /mnt
      volumeMounts:
      - name: data4
        mountPath: /mnt/data
      - name: output4
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'
   
  - name: process-data
    inputs:
      artifacts:
      - name: data
        path: /mnt/data/datasets/
        s3:
          key: '{{workflow.namespace}}/{{workflow.parameters.cvat-annotation-path}}'
    outputs:
      artifacts:
      - name: model
        path: /mnt/output
        optional: true
        s3:
          key: '{{workflow.namespace}}/{{workflow.parameters.cvat-output-path}}/{{workflow.name}}'
    container:
      image: pytorch/pytorch:latest
      command: [sh,-c]
      args:
      - |
        apt-get update && \
        apt-get install -y gcc g++ git && \
        python3 -m pip install setuptools torch==1.4.0 torchvision==0.5.0 tensorboard && \
        git clone --single-branch --branch dev https://github.com/onepanelio/nni.git && \
        cd nni/ && \
        python3 prepare_data.py --data_dir=/mnt/output/processed_data
      workingDir: /mnt
      volumeMounts:
      - name: data5
        mountPath: /mnt/data
      - name: output5
        mountPath: /mnt/output
    nodeSelector:
      beta.kubernetes.io/instance-type: '{{workflow.parameters.sys-node-pool}}'